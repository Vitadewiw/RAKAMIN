# -*- coding: utf-8 -*-
"""Salinan HR_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15LBoJlnfQycGOzg90nwK3tfL7cjDaaGt
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
import warnings

plt.style.use("default")
warnings.filterwarnings("ignore")

df = pd.read_csv('HR-Employee-Attrition.csv')
pd.set_option('display.max_columns', 100)
df.head()

"""1. Exploratory Data Analysis

1.1 Descriptive Statistics
"""

# Membagi dataset menjadi kolom numerik dan kategorik
numerical   = df.select_dtypes(exclude = 'object')
categorical = df.select_dtypes(include = 'object')

# Menampilkan statistika deskriptif kolom numerik
numerical.describe()

numerical.nunique()

# Menampilkan statistika deskriptif kolom kategorikal
categorical.describe()

"""1.2 Univariate Analysis"""

# Membuat pie chart

plt.pie(x = df['Attrition'].value_counts(), labels = ['No', 'Yes'], autopct = '%.1f%%',
        colors = ['cornflowerblue', 'orange'], explode = [0, 0.1])
plt.title('Ratio of Employee Attritions', fontsize = 15)
plt.show()

"""Berdasarkan ilustrasi di atas, dapat disimpulkan bahwa **16.1%** dari total karyawan memilih untuk keluar dari perusahaan sedangkan **83.9%** dari total karyawan memilih untuk bertahan."""

# Membuat list num_columns
num_columns =  ['MonthlyIncome', 'Age', 'DistanceFromHome', 'DailyRate', 'TotalWorkingYears',
                'YearsAtCompany', 'YearsInCurrentRole', 'YearsWithCurrManager']

# Mengatur ukuran gambar
fig, ax = plt.subplots(2, 4, figsize = (15,6))

# Membuat kdeplot
for i, col in enumerate(num_columns):
  ax1 = sns.kdeplot(x = df[df['Attrition'] == 'Yes'][col], fill = True, label = 'Yes', color = 'orange', edgecolor = 'black', linewidth = 1, alpha = 0.9, ax = ax[i//4, i%4])
  ax2 = sns.kdeplot(x = df[df['Attrition'] == 'No'][col], fill = True, label = 'No', color = 'cornflowerblue', edgecolor = 'black', linewidth = 1, alpha = 0.9, ax = ax[i//4, i%4])

  # Mengatur x label
  ax1.set_xlabel(col, fontweight = 'bold')

  # Mengatur y label
  if i in [0, 4]:
    ax1.set_ylabel('Density', fontweight = 'bold')
  else:
    ax1.set_ylabel('')

  # Menambah legend
  if i == 0:
    ax1.legend(title = 'Attrition')

plt.suptitle('Univariate Analysis for Numerical Features', fontsize = 15, fontweight = 'bold')
plt.tight_layout()
plt.show()

# Membuat list cat_columns
cat_columns = ['OverTime', 'JobSatisfaction','EnvironmentSatisfaction', 'RelationshipSatisfaction',
               'JobLevel', 'WorkLifeBalance', 'JobInvolvement', 'Department', 'JobRole']

# Membuat subplots
fig, ax = plt.subplots(3,3, figsize = (12, 12))

# Menghitung proporsi attrition untuk list cat_columns
for i, col in enumerate(cat_columns):
  df_cat = df.groupby(cat_columns[i])['Attrition'].value_counts(normalize = True).unstack()
  df_cat = df_cat[['Yes', 'No']]
  df_cat = df_cat.sort_values('Yes', ascending = False)

  # Membuat barchart
  ax1 = df_cat.plot.bar(stacked=True, color=['orange', 'cornflowerblue'], edgecolor = 'black', linewidth = 0.5, ax = ax[i//3, i%3])

  # Mengatur x label
  ax1.set_xlabel(col, fontweight = 'bold')

  # Mengatur y label
  if i in [0,3,6]:
    ax1.set_ylabel('Percentage %', fontweight = 'bold')

  # Mengatur x ticks
  if i in [7,8]:
    ax1.set_xticklabels(df_cat.index, rotation = 90)
  else:
    ax1.set_xticklabels(df_cat.index, rotation = 0)

  if i != 0:
    ax1.get_legend().remove()

plt.suptitle('Univariate Analysis for Categorical Features', fontsize = 15, fontweight = 'bold', y = 1)
plt.tight_layout()
plt.show()

"""1.3 Bivariate Analysis"""

# Adjust image size
plt.figure(figsize=(12, 12))

# Custom palette
palette = ['orange', 'cornflowerblue']

# Create a boxplot
for i in range(9):
    plt.subplot(3, 3, i+1)
    ax1 = sns.boxplot(x = cat_columns[i], y = "MonthlyIncome", data = df, hue = 'Attrition', palette = palette, linewidth = 0.7)

    # Adjust x label
    ax1.set_xlabel(cat_columns[i], fontsize = 10, fontweight = 'bold', labelpad = 10)

    # Adjust y label
    if i in [0, 3, 6]:
      ax1.set_ylabel('Monthly Income', fontsize = 10, fontweight = 'bold')
    else:
      ax1.set_ylabel('')

    # Adjust xticks
    if i in [7, 8]:
      ax1.set_xticklabels(ax1.get_xticklabels(), rotation = 90)

    # Add legend
    if i == 4:
      ax1.legend(title='Attrition', loc='lower right')
    else:
      ax1.get_legend().remove()

plt.suptitle('Bivariate Analysis Based on\nMonthly Income & Categorical Features', fontweight='bold', fontsize=15, y=1)
plt.tight_layout()
plt.show()

"""2. Data Preprocesing

2.1 Handle Missing Value
"""

df.info()

df.isna().sum()
print("Jumlah nilai kosong pada masing-masing kolom :")

"""2.2 Handle Duplicated Data"""

# Menampilkan jumlah data duplicate
df.duplicated().sum()
print("Jumlah data duplikat :")

"""2.3 Handle Outliers"""

# Menghapus outlier
from scipy import stats

filtered_entries = np.array([True] * len(df))
print(f'Jumlah baris sebelum penghapusan outliers : {len(df)}')

for col in ['MonthlyIncome', 'NumCompaniesWorked', 'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']:
    zscore = abs(stats.zscore(df[col])) # hitung absolute z-scorenya
    filtered_entries = (zscore < 3) & filtered_entries # keep yang kurang dari 3 absolute z-scorenya

df = df[filtered_entries] # filter, ambil z-score dibawah 3

print(f'Jumlah baris setelah penghapusan outliers : {len(df)}')

"""2.4 Feature Encoding"""

# Membuat map
BusinessTravel_map = {'Non-Travel': 0, 'Travel_Rarely': 1, 'Travel_Frequently': 2}

# Melakukan label encoding pada kolom bertipe kategorik
df['Attrition'] = LabelEncoder().fit_transform(df['Attrition'])
df['BusinessTravel'] = df['BusinessTravel'].map(BusinessTravel_map)
df['Gender'] = LabelEncoder().fit_transform(df['Gender'])
df['OverTime'] = LabelEncoder().fit_transform(df['OverTime'])

# Menampilkan data setelah dilakukan proses label encoding
df.head()

# Melakukan one-hot encoding kolom kategorik
for cat in categorical:
  if cat not in ['Attrition', 'BusinessTravel', 'Gender', 'OverTime', 'Over18']:
    df1 = pd.get_dummies(df[cat], prefix=cat)
    df  = df.drop(cat, axis = 1)
    df  = df.join(df1)

# Menampilkan data setelah dilakukan proses one-hot encoding
df.head()

df.info()

"""2.5 Feature Selection"""

# Menghapus kolom dengan nilai unik
df_new = df.drop(columns = ['EmployeeNumber', 'EmployeeCount', 'StandardHours', 'Over18'])
df_new.info()

# Menghilangkan kolom yang memiliki nilai korelasi rendah terhadap target (korelasi dibawah 0.05)
# Kolom target yang akan digunakan sebagai referensi
target_column = 'Attrition'

# Hitung korelasi terhadap kolom target
correlation_with_target = df_new.corr()[target_column].drop(target_column)

# Hilangkan kolom-kolom dengan korelasi di bawah 0.05 terhadap kolom target
threshold = 0.05
columns_to_drop = correlation_with_target[abs(correlation_with_target) < threshold].index
data_filtered = df_new.drop(columns=columns_to_drop)

data_filtered.info()

# Meletakkan kolom Attrition di urutan terakhir
data_filtered = data_filtered.drop('Attrition', axis=1)
data_filtered['Attrition'] = df_new['Attrition']

# Buat dan tampilkan heatmap
plt.figure(figsize=(27, 20))
sns.heatmap(data_filtered.corr(), cmap='viridis', annot=True, fmt=".2f", annot_kws={"size": 13})
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.show()

"""Terdapat multicollinearity atau korelasi yang memiliki nilai di atas 0.7 antara kolom JobLevel, MonthlyIncome dan TotalWorkingYears serta kolom YearsAtCompany, YearsInCurrentRole dan YearsWithCurrManager sehingga kita bisa memilih salah satu saja."""

df1 = pd.read_csv('cleaned_hr_dataset.csv')
df1.info()

"""2.6 Feature Engineering"""

# Menghapus kolom Attrition
data_filtered = data_filtered.drop('Attrition', axis = 1)

# Membuat fitur baru
data_filtered['EmployeeSatisfaction'] = ( df_new['EnvironmentSatisfaction'] + df_new['JobSatisfaction'] + df_new['RelationshipSatisfaction'] ) / 3
data_filtered['JobLevelSatisfaction'] = df_new['JobLevel'] * df_new['JobSatisfaction']

# Menambahkan kolom Attrition
data_filtered['Attrition'] = df_new['Attrition']

"""Menambah kolom baru
1. EmployeeSatisfaction

 Menggabungkan tiga aspek kepuasan karyawan menjadi satu skor rata-rata, sehingga mencerminkan kepuasan secara keseluruhan yang bisa menjadi faktor kuat penyebab Attrition

2. JobLevelSatisfaction

 Menggabungkan tingkat jabatan dan kepuasan kerja
"""

# Buat dan tampilkan heatmap
plt.figure(figsize=(27, 20))
sns.heatmap(data_filtered.corr(), cmap='viridis', annot=True, fmt=".2f", annot_kws={"size": 13})
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.show()

# Menghapus kolom yang memiliki korelasi lebih rendah dengan target
data_baru = data_filtered.drop(columns = ['JobSatisfaction',
                                          'RelationshipSatisfaction'])

"""Menghapus kolom yang memiliki korelasi rendah dengan target (Attrition)
- JobSatisfaction
- RelationshipSatisfaction
"""

# Menampilkan data baru
data_baru.info()

"""2.7 Standardization"""

# Menampilkan data setelah dilakukan proses scaling
data_baru.describe()

"""Setelah dilakukan transformasi kolom-kolom numerik memiliki simpangan baku mendekati 1 dan rata-rata mendekati 0.

2.8 Handle Class Imbalance
"""

# Membagi data menjadi target dan fitur
x = data_baru[[col for col in data_baru.columns if col not in ['Attrition']]]
y = data_baru['Attrition'].values

print("Jumlah perbandingan antara kelas attrition dan tidak attrition sebelum class imbalance :")
print(pd.Series(y).value_counts())

"""Berdasarkan informasi di atas, didapatkan bahwa perbandingan antara kelas attrition dan tidak attrition ada di sekitar 1:5, sehingga akan dilakukan proses handle class imbalance."""

# Melakukan handling class imbalance
from imblearn import over_sampling
x_over, y_over = over_sampling.SMOTE(sampling_strategy = 1).fit_resample(x, y)

print("Jumlah perbandingan antara kelas attrition dan tidak attrition setelah class imbalance :")
print(pd.Series(y_over).value_counts())

# Menggabungkan kembali data setelah dilakukan handling class imbalance
data_final = x_over
data_final['Attrition'] = y_over
data_final.info()

data_final.to_csv('HR_FINPRO.csv', index=False)

data_final.head()

"""3. Modeling

3.1 Split Data
"""

from sklearn.model_selection import train_test_split

# Pisahkan antara fitur (X) dengan target (y)
X = data_final.drop(columns=['Attrition'])
y = data_final[['Attrition']]

# Split data: 80% train, 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42, stratify=y)

# Tampilkan ukuran data hasil split
X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""3.2 Modeling"""

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pandas as pd

# Daftar model
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Support Vector Machine": SVC(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42)
}

# Fungsi evaluasi
def evaluate_models(models, X_train, X_test, y_train, y_test):
    results = []
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        results.append({
            "Model": name,
            "Accuracy": accuracy_score(y_test, y_pred),
            "Precision": precision_score(y_test, y_pred, zero_division=0),
            "Recall": recall_score(y_test, y_pred),
            "F1 Score": f1_score(y_test, y_pred)
        })
    return pd.DataFrame(results).sort_values(by="F1 Score", ascending=False)

# Evaluasi model (pastikan X_train, X_test, y_train, y_test sudah tersedia)
baseline_results = evaluate_models(models, X_train, X_test, y_train, y_test)
print(baseline_results)

from sklearn.metrics import confusion_matrix

# Daftar model yang akan dievaluasi
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(),
    "KNN": KNeighborsClassifier()
}

# Training dan plotting confusion matrix tiap model
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 10))
axes = axes.flatten()

for i, (name, model) in enumerate(models.items()):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)

    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['No Attrition', 'Attrition'],
                yticklabels=['No Attrition', 'Attrition'],
                ax=axes[i])
    axes[i].set_title(f"{name}")
    axes[i].set_xlabel('Predicted label')
    axes[i].set_ylabel('True label')

# Jika jumlah subplot lebih banyak dari model, hapus sisa plot kosong
for j in range(i+1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# X = semua fitur, y = Attrition
X = data_final.drop('Attrition', axis=1)
y = data_final['Attrition']

# Model Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X, y)

# Fitur yang relevan
importances = pd.Series(rf.feature_importances_, index=X.columns)
importances = importances.sort_values(ascending=False)

plt.figure(figsize=(10,6))
sns.barplot(x=importances[:15], y=importances.index[:15])
plt.title('Fitur Relevan')
plt.xlabel('Importance')
plt.ylabel('Fitur')
plt.tight_layout()
plt.show()

from sklearn.feature_selection import SelectKBest, chi2
from sklearn.preprocessing import MinMaxScaler

# Skala data agar cocok untuk chi2 (nilai harus positif)
scaler = MinMaxScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Pilih top 10 fitur terbaik
selector = SelectKBest(score_func=chi2, k=10)
selector.fit(X_scaled, y)

selected_features = X.columns[selector.get_support()]
print("Top 10 fitur terpilih (Chi-Square):")
print(selected_features)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report
)
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Load dataset
df = pd.read_csv("HR_FINPRO.csv")

# 2. Pisahkan fitur dan target
X = df.drop(columns=["Attrition"])
y = df["Attrition"]

# 3. Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 4. Buat dan latih model Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# 5. Prediksi
y_pred_rf = rf_model.predict(X_test)

# 6. Evaluasi
accuracy = accuracy_score(y_test, y_pred_rf)
precision = precision_score(y_test, y_pred_rf)
recall = recall_score(y_test, y_pred_rf)
f1 = f1_score(y_test, y_pred_rf)
conf_matrix = confusion_matrix(y_test, y_pred_rf)
class_report = classification_report(y_test, y_pred_rf)

# 7. Tampilkan hasil evaluasi
print("Evaluasi Model Random Forest")
print(f"Akurasi   : {accuracy:.2%}")
print(f"Precision : {precision:.2%}")
print(f"Recall    : {recall:.2%}")
print(f"F1-Score  : {f1:.2%}\n")
print("Confusion Matrix")
print(pd.DataFrame(conf_matrix, index=["Aktual 0", "Aktual 1"], columns=["Prediksi 0", "Prediksi 1"]))
print("\nClassification Report")
print(class_report)

# 8. Visualisasi confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Greens",
            xticklabels=["Prediksi 0", "Prediksi 1"],
            yticklabels=["Aktual 0", "Aktual 1"])
plt.title("Confusion Matrix - Random Forest")
plt.ylabel("Aktual")
plt.xlabel("Prediksi")
plt.tight_layout()
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score

# 1. Probabilitas prediksi kelas positif (Attrition = 1)
y_proba_rf = rf_model.predict_proba(X_test)[:, 1]

# 2. Hitung ROC curve dan AUC
fpr, tpr, thresholds = roc_curve(y_test, y_proba_rf)
auc_score = roc_auc_score(y_test, y_proba_rf)

# 3. Plot ROC Curve
plt.figure(figsize=(6, 4))
plt.plot(fpr, tpr, label=f"AUC = {auc_score:.2f}", color="darkorange", linewidth=2)
plt.plot([0, 1], [0, 1], 'k--', label="Random Classifier")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Random Forest")
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
plt.show()

# 4. Cetak AUC
print(f"🔷 AUC Score: {auc_score:.2%}")

maritalstatus_fairness = df.groupby('MaritalStatus_Single')['Attrition'].agg(['count', 'sum']).assign(
    Attrition_Rate=lambda x: x['sum'] / x['count']
    ).rename(columns={'count': 'Total', 'sum': 'Jumlah_Attrition'})

# Visualisasi attrition rate berdasarkan OverTime
plt.figure(figsize=(6, 5))
sns.barplot(x=maritalstatus_fairness.index, y=maritalstatus_fairness['Attrition_Rate'], palette='viridis')

plt.title('Attrition Status Pernikahan (MaritalStatus)')
plt.xlabel('MaritalStatus')
plt.ylabel('Attrition Rate')
plt.ylim(0, 1)
plt.xticks([0, 1], ['Married', 'Single'])

for i, rate in enumerate(maritalstatus_fairness['Attrition_Rate']):
    plt.text(i, rate + 0.02, f'{rate:.2%}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

df['JobLevelSatisfaction_group'] = pd.cut(
    (df['JobLevelSatisfaction'] - df['JobLevelSatisfaction'].mean()) / df['JobLevelSatisfaction'].std(),
    bins=[-np.inf, -0.5, 0.5, np.inf],
    labels=['Low', 'Medium', 'High']
)
job_fairness = df.groupby('JobLevelSatisfaction_group')['Attrition'].agg(['count', 'sum']).assign(
    Attrition_Rate=lambda x: x['sum'] / x['count']
).rename(columns={'count': 'Total', 'sum': 'Jumlah_Attrition'})

# Visualisasi attrition rate berdasarkan JobLevelSatisfaction
plt.figure(figsize=(8, 5))
sns.barplot(x=job_fairness.index, y=job_fairness['Attrition_Rate'], palette='viridis')

plt.title('Attrition Rate Kepuasan Karyawan')
plt.xlabel('Kepuasan Karyawan')
plt.ylabel('Attrition Rate')
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)

for i, rate in enumerate(job_fairness['Attrition_Rate']):
    plt.text(i, rate + 0.02, f'{rate:.2%}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

df['MonthlyIncome_group'] = pd.cut(
    (df['MonthlyIncome'] - df['MonthlyIncome'].mean()) / df['MonthlyIncome'].std(),
    bins=[-np.inf, -0.5, 0.5, np.inf],
    labels=['Low', 'Medium', 'High']
)
income_fairness = df.groupby('MonthlyIncome_group')['Attrition'].agg(['count', 'sum']).assign(
    Attrition_Rate=lambda x: x['sum'] / x['count']
).rename(columns={'count': 'Total', 'sum': 'Jumlah_Attrition'})

# Visualisasi attrition rate berdasarkan MonthlyIncome
plt.figure(figsize=(8, 5))
sns.barplot(x=income_fairness.index, y=income_fairness['Attrition_Rate'], palette='viridis')

plt.title('Attrition Rate Berdasarkan Pendapatan Bulanan')
plt.xlabel('Pendapatan Bulanan')
plt.ylabel('Attrition Rate')
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)

for i, rate in enumerate(income_fairness['Attrition_Rate']):
    plt.text(i, rate + 0.02, f'{rate:.2%}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

stock_fairness = df.groupby('StockOptionLevel')['Attrition'].agg(['count', 'sum']).assign(
    Attrition_Rate=lambda x: x['sum'] / x['count']
).rename(columns={'count': 'Total', 'sum': 'Jumlah_Attrition'})

# Visualisasi attrition rate berdasarkan StockOptionLevel
plt.figure(figsize=(8, 5))
sns.barplot(x=stock_fairness.index, y=stock_fairness['Attrition_Rate'], palette='viridis')

plt.title('Attrition Rate Berdasarkan Opsi Saham')
plt.xlabel('Opsi Saham')
plt.ylabel('Attrition Rate')
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)

for i, rate in enumerate(stock_fairness['Attrition_Rate']):
    plt.text(i, rate + 0.02, f'{rate:.2%}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

"""StockOptionLevel biasanya adalah kode kategorikal dari sistem HR yang artinya:

0 = Tidak memiliki opsi saham

1 = Opsi saham level rendah

2 = Opsi saham level sedang

3 = Opsi saham level tinggi
"""

jobin_fairness = df.groupby('JobInvolvement')['Attrition'].agg(['count', 'sum']).assign(
    Attrition_Rate=lambda x: x['sum'] / x['count']
).rename(columns={'count': 'Total', 'sum': 'Jumlah_Attrition'})

# Visualisasi attrition rate berdasarkan JobInvolvement
plt.figure(figsize=(8, 5))
sns.barplot(x=jobin_fairness.index, y=jobin_fairness['Attrition_Rate'], palette='viridis')

plt.title('Attrition Rate Berdasarkan Partisipasi Kerja')
plt.xlabel('Partisipasi Kerja')
plt.ylabel('Attrition Rate')
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)

for i, rate in enumerate(jobin_fairness['Attrition_Rate']):
    plt.text(i, rate + 0.02, f'{rate:.2%}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

df['EmployeeSatisfaction_group'] = pd.cut(
    (df['EmployeeSatisfaction'] - df['EmployeeSatisfaction'].mean()) / df['EmployeeSatisfaction'].std(),
    bins=[-np.inf, -0.5, 0.5, np.inf],
    labels=['Low', 'Medium', 'High']
)
employee_fairness = df.groupby('EmployeeSatisfaction_group')['Attrition'].agg(['count', 'sum']).assign(
    Attrition_Rate=lambda x: x['sum'] / x['count']
).rename(columns={'count': 'Total', 'sum': 'Jumlah_Attrition'})

# Visualisasi attrition rate berdasarkan JobInvolvement
plt.figure(figsize=(8, 5))
sns.barplot(x=employee_fairness.index, y=employee_fairness['Attrition_Rate'], palette='viridis')

plt.title('Attrition Rate Berdasarkan Kepuasan Karyawan terhadap Lingkungan Kerja')
plt.xlabel('Kepuasan Karyawan')
plt.ylabel('Attrition Rate')
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)

for i, rate in enumerate(employee_fairness['Attrition_Rate']):
    plt.text(i, rate + 0.02, f'{rate:.2%}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

"""Employee satisfaction, dalam bahasa Indonesia disebut kepuasan karyawan, adalah tingkat perasaan senang dan kepuasan yang dirasakan karyawan terhadap pekerjaan dan lingkungan kerja mereka. Ini mencakup berbagai aspek, mulai dari gaji dan tunjangan, hubungan dengan atasan dan rekan kerja, hingga budaya perusahaan dan peluang pengembangan karir. Karyawan yang puas cenderung lebih termotivasi, berkinerja lebih baik, dan lebih terlibat dalam pekerjaan mereka."""

df['DailyRate_group'] = pd.cut(
    (df['DailyRate'] - df['DailyRate'].mean()) / df['DailyRate'].std(),
    bins=[-np.inf, -0.5, 0.5, np.inf],
    labels=['Low', 'Medium', 'High']
)
daily_fairness = df.groupby('DailyRate_group')['Attrition'].agg(['count', 'sum']).assign(
    Attrition_Rate=lambda x: x['sum'] / x['count']
).rename(columns={'count': 'Total', 'sum': 'Jumlah_Attrition'})

# Visualisasi attrition rate berdasarkan DailyRate
plt.figure(figsize=(8, 5))
sns.barplot(x=daily_fairness.index, y=daily_fairness['Attrition_Rate'], palette='viridis')

plt.title('Attrition Rate Berdasarkan Tarif Gaji Harian')
plt.xlabel('Tarif Gaji Harian')
plt.ylabel('Attrition Rate')
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)

for i, rate in enumerate(daily_fairness['Attrition_Rate']):
    plt.text(i, rate + 0.02, f'{rate:.2%}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

df['DistanceFromHome_group'] = pd.cut(
    (df['DistanceFromHome'] - df['DistanceFromHome'].mean()) / df['DistanceFromHome'].std(),
    bins=[-np.inf, -0.5, 0.5, np.inf],
    labels=['Low', 'Medium', 'High']
)
distance_fairness = df.groupby('DistanceFromHome_group')['Attrition'].agg(['count', 'sum']).assign(
    Attrition_Rate=lambda x: x['sum'] / x['count']
).rename(columns={'count': 'Total', 'sum': 'Jumlah_Attrition'})

# Visualisasi attrition rate berdasarkan DistanceFromHome
plt.figure(figsize=(8, 5))
sns.barplot(x=distance_fairness.index, y=distance_fairness['Attrition_Rate'], palette='viridis')

plt.title('Attrition Rate Berdasarkan Jarak dari Rumah')
plt.xlabel('Jarak dari Rumah')
plt.ylabel('Attrition Rate')
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)

for i, rate in enumerate(distance_fairness['Attrition_Rate']):
    plt.text(i, rate + 0.02, f'{rate:.2%}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np

df = pd.read_csv('HR_FINPRO.csv')

# Hitung z-score untuk kolom Age
df['Age_zscore'] = (df['Age'] - df['Age'].mean()) / df['Age'].std()

# Kelompokkan usia berdasarkan z-score
df['Age_Group'] = pd.cut(df['Age_zscore'],
                         bins=[-np.inf, -0.5, 0.5, np.inf],
                         labels=['Muda', 'Dewasa', 'Tua'])

# Hitung jumlah dan persentase attrition per kelompok usia
age_fairness = df.groupby('Age_Group')['Attrition'].agg(['count', 'sum'])
age_fairness['Attrition_Rate'] = age_fairness['sum'] / age_fairness['count']
age_fairness = age_fairness.rename(columns={
    'count': 'Total',
    'sum': 'Jumlah_Attrition'
})

# Tampilkan hasil
print(age_fairness.reset_index())

import matplotlib.pyplot as plt
import seaborn as sns

# Visualisasi attrition rate berdasarkan Age Group
plt.figure(figsize=(8, 5))
sns.barplot(x=age_fairness.index, y=age_fairness['Attrition_Rate'], palette='viridis')

plt.title('Attrition Rate Berdasarkan Kelompok Usia')
plt.xlabel('Kelompok Usia')
plt.ylabel('Attrition Rate')
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)

for i, rate in enumerate(age_fairness['Attrition_Rate']):
    plt.text(i, rate + 0.02, f'{rate:.2%}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

envi_fairness = df.groupby('EnvironmentSatisfaction')['Attrition'].agg(['count', 'sum']).assign(
    Attrition_Rate=lambda x: x['sum'] / x['count']
).rename(columns={'count': 'Total', 'sum': 'Jumlah_Attrition'})

# Visualisasi attrition rate berdasarkan EnvironmentSatisfaction
plt.figure(figsize=(8, 5))
sns.barplot(x=envi_fairness.index, y=envi_fairness['Attrition_Rate'], palette='viridis')

plt.title('Attrition Rate Berdasarkan Kepuasan Lingkungan')
plt.xlabel('Kepuasan Lingkungan')
plt.ylabel('Attrition Rate')
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)

for i, rate in enumerate(envi_fairness['Attrition_Rate']):
    plt.text(i, rate + 0.02, f'{rate:.2%}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

pip install lime

# --- 1. Import library ---
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from lime.lime_tabular import LimeTabularExplainer

# --- 2. Baca dataset ---
df = pd.read_csv("HR_FINPRO.csv")

# --- 3. Pisahkan fitur dan target ---
X = df.drop("Attrition", axis=1)
y = df["Attrition"]

# --- 4. Split data tanpa standarisasi (karena Random Forest tidak membutuhkannya) ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# --- 5. Latih Random Forest ---
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# --- 6. Evaluasi model ---
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

# --- 7. Inisialisasi LIME ---
explainer = LimeTabularExplainer(
    training_data=X_train.values,
    feature_names=X.columns.tolist(),
    class_names=["No Attrition", "Attrition"],
    mode='classification'
)

# --- 8. Pilih salah satu contoh dan jelaskan ---
i = 0  # ganti dengan index lain
exp = explainer.explain_instance(
    data_row=X_test.iloc[i].values,
    predict_fn=model.predict_proba,
    num_features=10
)

# --- 9. Tampilkan penjelasan ---
exp.show_in_notebook(show_table=True)

# Versi teks
print("\nExplanation (Top Features):")
for feature, weight in exp.as_list():
    print(f"{feature}: {weight:.4f}")

import matplotlib.pyplot as plt
from lime.lime_tabular import LimeTabularExplainer

# Inisialisasi LimeTabularExplainer (pastikan data sudah siap)
# Assume X_train, X_test, y_train, y_test, and model are already defined from previous cells
explainer = LimeTabularExplainer(
    training_data=X_train.values,
    feature_names=X.columns.tolist(),
    class_names=["No Attrition", "Attrition"],
    mode='classification'
)

# Pilih satu data uji untuk dijelaskan
i = 0
exp = explainer.explain_instance(
    data_row=X_test.iloc[i].values,  # Access the row by index and get the values as a numpy array
    predict_fn=model.predict_proba,
    num_features=10
)

# Ambil top 10 fitur dan bobotnya
top_features = exp.as_list()

# Pisahkan nama fitur dan bobot untuk plotting
features = [f[0] for f in top_features]
weights = [f[1] for f in top_features]

# Buat grafik horizontal bar
plt.figure(figsize=(8,6))
colors = ['green' if w > 0 else 'red' for w in weights]
plt.barh(features, weights, color=colors)
plt.xlabel('Contribution to Prediction')
plt.title('Top 10 Feature Contributions by LIME')
plt.gca().invert_yaxis()  # agar fitur paling penting ada di atas
plt.show()

# Top 10 selected features based on previous analysis
selected_features = [
    'MaritalStatus_Single','JobLevelSatisfaction','MonthlyIncome',
    'StockOptionLevel','JobInvolvement','EmployeeSatisfaction',
    'DailyRate','DistanceFromHome','Age','EnvironmentSatisfaction'
]

# Split data
X = df[selected_features]
y = df['Attrition']

# Train Random Forest model using selected top 10 features
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X, y)

# Import joblib
import joblib

# Save model
model_path = "rf_top_10.joblib"
joblib.dump(model, model_path)

model_path

